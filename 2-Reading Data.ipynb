{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d96022-6e30-4931-b70f-1d3aee0745e0",
   "metadata": {},
   "source": [
    "# Notebook 2: Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7ce69-b1fa-4046-ad3a-868aa6b3404f",
   "metadata": {},
   "source": [
    "Welcome! The main goal of this notebook is to read the Cubeset data, and get know its different calsses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5059112-490b-4c53-9c84-489bd09d5316",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d95d4-1c54-40dc-9546-e9f9b95ee932",
   "metadata": {},
   "source": [
    "The dataset we will be working with contains five classes, described as follows:\n",
    "- **Blurry**: Data captured while the satellite is in motion, resulting in blurred images.\n",
    "- **Corrupt**: Images with defects from improper camera priming or stray light.\n",
    "- **Missing Data**: Images with partial or complete data loss.\n",
    "- **Noisy**: Images over-saturated with noise from radiation or other sources.\n",
    "- **Priority**: Clear images suitable for scientific analysis on the ground."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288bdedc-c265-4079-a8f4-9cb7bfbcd000",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448f8f6-21d5-4af4-bccd-45990ac01ada",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb94d2d-f310-413b-b718-e52f41ad5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.pre import read_images_from_folder # A custom function that reads .jpg images from a folder and returns them as a stacked NumPy array.\n",
    "import os  # Importing the 'os' module for interacting with the operating system, such as handling file paths.\n",
    "from concurrent.futures import ProcessPoolExecutor  # Importing 'ProcessPoolExecutor' for parallel execution using multiple processors.\n",
    "import matplotlib.pyplot as plt  # Importing Matplotlib for creating visualizations and plots.\n",
    "import random  # Importing the 'random' module for generating random numbers and making random selections.\n",
    "import numpy as np  # Importing NumPy, a library for numerical operations, used here for handling and manipulating image data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ce9fcc-7d34-4030-913f-87ea5da2da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"] # The 5 classes of our data\n",
    "base_dir = \"data/\" # Where the data sets\n",
    "images_by_class = {} # Dictionary to store images by class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618e84a-8427-49e1-a2bf-0369900d2000",
   "metadata": {},
   "source": [
    "#### Read images from each folder/class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b26c061-a218-4b41-a62a-7b5844f76fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read images from a specific folder\n",
    "# This function is designed to be used with ProcessPoolExecutor for parallel processing.\n",
    "# It takes a folder name, constructs the full path, reads all images, and returns both the folder name and the images.\n",
    "def process_folder(folder):\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    images = read_images_from_folder(folder_path)\n",
    "    return folder, images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d312d932-66e9-4a77-966f-df7e2f632100",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abd19a-4d86-4b96-be52-ee08963cf071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ProcessPoolExecutor to parallelize the folder processing\n",
    "with ProcessPoolExecutor(max_workers=5) as executor:\n",
    "    results = executor.map(process_folder, folders)\n",
    "\n",
    "# Collect the results\n",
    "for folder, images in results:\n",
    "    images_by_class[folder] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886fb9a-a6ee-4fca-b5ad-d80d5f089e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = 0  # Initialize a counter for the total number of images\n",
    "\n",
    "for folder, images in images_by_class.items():\n",
    "    num_images = len(images)\n",
    "    print(f\"Class '{folder}': {num_images} images read.\")\n",
    "    total_images += num_images  # Add the number of images in the current class to the total\n",
    "\n",
    "# Print the total number of images for all classes\n",
    "print(f\"Total images read across all classes: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ebfbe-24d6-4093-90e3-11a214c1a514",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d18c67-2fc6-4926-94b2-d4024c034e1c",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e56e4-4dd0-44e1-94d2-5ef6c0b499bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# Assuming images_by_class is your dictionary\n",
    "# where keys are class names and values are numpy arrays of images\n",
    "\n",
    "for folder, images in images_by_class.items():    \n",
    "    # Ensure we have at least 5 images\n",
    "    num_images_to_display = min(5, len(images))\n",
    "    \n",
    "    # Randomly select 5 images\n",
    "    random_indices = random.sample(range(len(images)), num_images_to_display)\n",
    "    selected_images = images[random_indices] / 255.0\n",
    "\n",
    "    # Plot the selected images\n",
    "    fig, axes = plt.subplots(1, num_images_to_display, figsize=(20, 4))\n",
    "    fig.suptitle(f'Class: {folder}', fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(selected_images[i])\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b099a4-1a15-4a54-9d04-f2a8cbd7aa46",
   "metadata": {},
   "source": [
    "The images in the dataset appear to have distinct visual characteristics that make them easy to classify by eye. For example, “Blurry,” “Corrupt,” and “Missing Data” images each have unique visual patterns and anomalies that differentiate them from one another. Given these clear differences, we can reasonably expect that machine learning models would also be able to classify these images with high accuracy, as the features that distinguish each class are visually pronounced and easily identifiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9840b4f-08b2-4e59-a324-a15342731de2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88a0bb-fbf8-43ac-a025-8941eb053dc8",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c83ed5-2bae-48ef-8a69-b3680d3a0cbc",
   "metadata": {},
   "source": [
    "#### Converting Images and Labels to NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b379e-200a-4f27-9ad3-112fa73c3d46",
   "metadata": {},
   "source": [
    "Now we save the data into a NumPy array for easier use in machine learning, and to realise that we can follow these steps:\n",
    "\n",
    "-\tCombine All Images and Labels: It gathers all images and their corresponding labels into two lists.\n",
    "-\tConvert to NumPy Arrays: It converts these lists into NumPy arrays, which are easier to handle for machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c62768-0b63-49eb-8630-e3e445ed87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to hold all images and labels\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the images_by_class dictionary to collect images and their labels\n",
    "for label, images in images_by_class.items():\n",
    "    all_images.extend(images)  # Add all images to the list\n",
    "    all_labels.extend([label] * len(images))  # Add the corresponding label for each image\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "all_images_np = np.array(all_images)\n",
    "all_labels_np = np.array(all_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b16bb2-c26e-4625-842f-8231ed6689ff",
   "metadata": {},
   "source": [
    "#### Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f35996-275d-4729-90f4-7f14c5c9a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels_encoded = label_encoder.fit_transform(all_labels_np)\n",
    "\n",
    "print(\"Original Labels:\", all_labels_np)\n",
    "print(\"Encoded Labels:\", all_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53940c7c-b177-44fa-a4a7-8265fa0a346f",
   "metadata": {},
   "source": [
    "#### Shuffling and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ab8fa-f19d-469c-8567-c30950d575fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # Importing train_test_split for splitting data into training and testing sets\n",
    "\n",
    "# Split the data: 80% training, 20% test\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(all_images_np, all_labels_encoded, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(f\"Training data: {len(train_images)} images\")\n",
    "print(f\"Testing data: {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d4bda-0ca6-40cb-bcf4-7fd24ef854ec",
   "metadata": {},
   "source": [
    "#### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7b389-acca-4289-a2d9-7ed1bc574169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined images and labels arrays to disk for future use\n",
    "np.save('train_images.npy', train_images)\n",
    "np.save('test_images.npy', test_images)\n",
    "np.save('train_labels.npy', train_labels)\n",
    "np.save('test_labels.npy', test_labels)\n",
    "\n",
    "print(\"Data saved successfully as NumPy arrays.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5a47c-b6b0-4948-ab8f-0f6b0db0530f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f94df-fad7-4384-8f39-07c6ea2a42f8",
   "metadata": {},
   "source": [
    "### Finally, removing data from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd31cb4-ea77-45bf-86ac-bf1c5e7510e6",
   "metadata": {},
   "source": [
    "**⚠️ Important Notice**: Since this code is being executed in a shared environment (ilifu), freeing up memory is crucial to ensure efficient resource usage. By removing unused data, it helps prevent memory bottlenecks that could affect not only your work but also the performance of other users relying on the shared hardware. This is especially important when working with large datasets (like in our case), as excessive memory usage can slow down the overall system and reduce availability for others using the same resources.\n",
    "\n",
    "**Make sure to follow this same practice when you develop your own pipeline during the hackathon to optimize performance and resource allocation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919afa30-eff6-4a3c-b670-47c3675f0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Remove the data from memory\n",
    "del train_images, test_images, train_labels, test_labels, all_images_np, all_labels_np\n",
    "\n",
    "# Force garbage collection to free up memory\n",
    "gc.collect()\n",
    "\n",
    "print(\"Data removed from memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33df2f-4646-47c3-bbe3-72b09e15f7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CubeHackKer",
   "language": "python",
   "name": "cubehackker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
