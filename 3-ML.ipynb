{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df38459-6403-4c59-8bf9-d4f00192f492",
   "metadata": {},
   "source": [
    "# Notebook 3: Classification Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324361f-daa8-4d9e-a5b4-3ac5465c9a6b",
   "metadata": {},
   "source": [
    "In this notebook, we will use a classical machine learning method to classify the astronomical data saved in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e4c998-a020-48c1-b7b0-1b3a755e733e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c7fbc-fa08-4312-ae32-88e30eb1d673",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a811c1b4-4512-4139-99a5-469776428dcc",
   "metadata": {},
   "source": [
    "First, we’ll load the saved image and label data from the NumPy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f6b6f-23c3-4017-b263-4d6204a44996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Importing NumPy for numerical operations and array handling\n",
    "\n",
    "# Load the training images and labels back from the saved NumPy files\n",
    "train_images = np.load('train_images.npy')  # Load image training data\n",
    "train_labels = np.load('train_labels.npy')  # Load label training data\n",
    "\n",
    "\n",
    "print(\"Training Data loaded successfully from NumPy files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e2a76-0d8b-4f5f-9c6d-a1d15474a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd935ff-1587-4a25-91ca-80dc157bf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204e579-2d19-4b8f-9a9f-f4af212b3417",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a94cb-00bd-4e79-ad42-ebc9652fbf18",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b7ae3-5950-44f2-80c2-749076b1ab0a",
   "metadata": {},
   "source": [
    "Now, we will further pre-process the trainig images to simplify the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7a7d9-5f13-4b32-8f4b-37e65d66ff28",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85633d36-aea5-4d2f-9481-b6ff46dedcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Normalize the training data\n",
    "\n",
    "# Scaling pixel values to be between 0 and 1\n",
    "train_images_pre = train_images.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c98aec-f45f-4373-8dca-908140d35542",
   "metadata": {},
   "source": [
    "##### **⚠️ Freeing up Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3db9e2-7870-44c0-b849-c2bdb0b31c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Since we will no longer need the original training data (train_images), we can remove it from memory\n",
    "del train_images\n",
    "\n",
    "# Force garbage collection to free up memory\n",
    "gc.collect()\n",
    "\n",
    "print(\"train_images removed from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c883d3f-38a6-47f0-b7d0-a5eccf0f22a9",
   "metadata": {},
   "source": [
    "### Grayscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444043c-5a41-4b6d-8358-e56ea8d26053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Convert images to grayscale, transforming them from RGB (3 channels) to a single channel (grayscale).\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Apply grayscale conversion to each image\n",
    "train_images_pre = np.array([rgb2gray(image) for image in train_images_pre])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64864b13-e7cf-4888-aad2-942f29a70220",
   "metadata": {},
   "source": [
    "### Downscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7bebb-8676-4297-8cc6-db3de403c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Downscale images to 64x64 pixels from 512x512\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Resize images to 64x64 pixels\n",
    "train_images_pre = np.array([resize(image, (64, 64), anti_aliasing=True) for image in train_images_pre])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d741968-50bd-4fae-a16e-639d1774214c",
   "metadata": {},
   "source": [
    "### Now, Visualizing the 5 classes after pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7dd90-943b-49fe-a10b-4ad71d6cdbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2851e-5124-473b-84dc-e496ee545922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # Ensure NumPy is imported\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Class names as a list\n",
    "class_names = ['Blurry', 'Corrupt', 'Missing Data', 'Noisy', 'Priority']\n",
    "\n",
    "# Number of images per class to display\n",
    "num_images_per_class = 5\n",
    "\n",
    "# Prepare the figure with appropriate size\n",
    "fig, axes = plt.subplots(nrows=5, ncols=num_images_per_class, figsize=(15, 10))\n",
    "\n",
    "for class_index, class_name in enumerate(class_names):\n",
    "    # Get indices of images belonging to the current class\n",
    "    indices = np.where(train_labels == class_index)[0]\n",
    "    # Randomly select image indices using the fixed seed\n",
    "    selected_indices = np.random.choice(indices, size=num_images_per_class, replace=False)\n",
    "    for i, img_index in enumerate(selected_indices):\n",
    "        # Get the corresponding image\n",
    "        img = train_images_pre[img_index]\n",
    "        # Access the appropriate axes\n",
    "        ax = axes[class_index, i]\n",
    "        # Display the image\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        # Turn off axis ticks and labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # Remove the frame\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "    # Set the class label on the left of the row\n",
    "    axes[class_index, 0].set_ylabel(class_name, rotation=90, size='large', labelpad=20, va='center')\n",
    "\n",
    "# Adjust the subplot parameters to make room for the labels\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.05, hspace=0.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247fd54-426c-41f5-ae70-104fc1cc4049",
   "metadata": {},
   "source": [
    "After reviewing the pre-processed images, it appears that reducing the size from 512x512 to 64x64 may not have been the best choice. Visually, it has become more challenging to distinguish between the **Priority**, **Noisy**, and **Blurry** categories. Now, let’s apply a machine learning method to classify these images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3950ac-b778-440e-9d1c-b2acdcb42f95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920f428-c5a6-4f7b-a07a-52392896719e",
   "metadata": {},
   "source": [
    "## ML Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a935e9a-05d9-4556-82c2-366fb7b08368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let us Flatten the training images\n",
    "num_train_samples = train_images_pre.shape[0]\n",
    "train_images_pre = train_images_pre.reshape(num_train_samples, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77290125-274d-4084-a0e9-1ebca479a52e",
   "metadata": {},
   "source": [
    "### Train the Stochastic Gradient Descent (SGD) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1105699-f55f-4208-bc3f-1797f82a3e9d",
   "metadata": {},
   "source": [
    "The Stochastic Gradient Descent (SGD) model refers to algorithms that use the stochastic gradient descent optimization method to train machine learning models. The SGDClassifier is a powerful tool for training linear models efficiently, especially when dealing with large datasets. Its speed comes from updating model parameters incrementally using individual samples or small batches, significantly reducing the computational overhead per iteration compared to traditional gradient descent methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5efcd-59d1-411f-b666-52bac92e0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import pickle\n",
    "\n",
    "# Create the stochastic gradient descent model\n",
    "\n",
    "sgd_model = SGDClassifier( loss='log_loss', max_iter=10000, n_jobs=4, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "sgd_model.fit(train_images_pre, train_labels)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('sgd_model.pkl', 'wb') as file:\n",
    "    pickle.dump(sgd_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8545012-9a47-4340-a4ca-6fc3bf204502",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41027dd0-ec8f-4a99-97ab-c4420cb2d6e0",
   "metadata": {},
   "source": [
    "##### **⚠️ Freeing up Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b841767-8e4a-4289-b106-7e10a7ca4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Remove the data from memory\n",
    "del train_images_pre, train_labels\n",
    "\n",
    "# Force garbage collection to free up memory\n",
    "gc.collect()\n",
    "\n",
    "print(\"Data removed from memory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CubeHackKer",
   "language": "python",
   "name": "cubehackker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
