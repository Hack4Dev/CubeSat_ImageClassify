{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ed05bb-fe72-45c8-aaf4-f067ee02838e",
   "metadata": {},
   "source": [
    "# Notebook 4: Classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38388419-5a1e-458f-9a07-1179014901ba",
   "metadata": {},
   "source": [
    "**Only run it if you’re adopting or experimenting with this model, as it can take up to two hours to train.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0cbf42-add7-486e-9e2d-6f04051b812e",
   "metadata": {},
   "source": [
    "In this notebook, we will use a CNN model to classify the images, following the approach used in the following [paper](https://ui.adsabs.harvard.edu/abs/2023SPIE12729E..0KC/abstract)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13095d08-82fa-49dc-8613-e8d4d1320555",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f39eb1-6f50-40c3-8468-226c0c8ee6b4",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f576c9-784f-49d2-bf5d-6978edeb89d4",
   "metadata": {},
   "source": [
    "First, we’ll load the saved image and label data from the NumPy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a8dd1-52ed-4514-8cd1-a59980fab45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Importing NumPy for numerical operations and array handling\n",
    "\n",
    "# Load the images and labels back from the saved NumPy files\n",
    "train_images = np.load('train_images.npy')  # Load image training data\n",
    "train_labels = np.load('train_labels.npy')  # Load label training data\n",
    "\n",
    "print(\"Data loaded successfully from NumPy files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953fc9a-d986-47e1-8872-213f8518cdb7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a46294-7dfd-46c0-9146-d53220c58dbb",
   "metadata": {},
   "source": [
    "### Train CubeCatNet CNN mdoel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c005cb-a745-4594-8aab-15b67e0fcdac",
   "metadata": {},
   "source": [
    "We will define and train a Convolutional Neural Network (CNN) model that was defined in [link](https://ui.adsabs.harvard.edu/abs/2023SPIE12729E..0KC/abstract)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54646112-a70d-4764-93bc-7f0b44e267b1",
   "metadata": {},
   "source": [
    "**⚠️**: When running this model, or any other deep learning model, make sure it’s not being run in parallel with your other team members. Running multiple models simultaneously on shared resources like CPUs can severely impact performance, leading to slower training times and potential resource conflicts. Coordinate with your team to ensure efficient use of the available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7dbc5a-b183-4974-a3fd-7ce74c4fa66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  # Importing Sequential to build the model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense  # Importing necessary layers for the CNN\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode the labels (assuming you have 5 classes)\n",
    "train_labels = to_categorical(train_labels, num_classes=5)\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(512, 512, 3)),  # Convolutional layer + ReLU activation\n",
    "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
    "    Conv2D(32, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
    "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
    "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
    "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
    "    GlobalAveragePooling2D(),  # Global average pooling layer\n",
    "    Dense(5, activation='softmax')  # Output layer with 5 neurons (one for each class) + Softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model with appropriate loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Model defined and compiled successfully.\")\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,  # Number of epochs\n",
    "    batch_size=64,  # Batch size\n",
    ")\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5cfc3-f2cd-4918-a85f-b3f1f7a9e505",
   "metadata": {},
   "source": [
    "##### **⚠️ Freeing up Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17f896-bbef-4caa-9b56-ba9d228dfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Since we will no longer need the original training data (train_images), we can remove it from memory\n",
    "del train_images, train_labels\n",
    "\n",
    "# Force garbage collection to free up memory\n",
    "gc.collect()\n",
    "\n",
    "print(\"train_images, and train_labels removed from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01be5fd-f911-410b-81e4-f0cd21f4cb4f",
   "metadata": {},
   "source": [
    "#### Saving the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c650f7-cf36-4108-ad8b-b6cb7fbff267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('cnn_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9d935-fda3-4ea3-8b33-4d5bd7cefc3a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc867bfa-7257-4523-a593-6ee21c8a4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now proceed to remove the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406d3d2-e4f3-47b9-a117-b18a1b48e808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CubeHackKer",
   "language": "python",
   "name": "cubehackker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
